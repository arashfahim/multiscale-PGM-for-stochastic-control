{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc9bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from scipy import misc\n",
    "import matplotlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "font = font_manager.FontProperties(style='normal', size=20)\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath}')\n",
    "%matplotlib inline\n",
    "# matplotlib.use('Qt5Agg')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "#import cvxpy as cp\n",
    "from scipy.optimize import fsolve\n",
    "from IPython.display import Markdown\n",
    "torch.set_default_dtype(torch.float64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19375a6",
   "metadata": {},
   "source": [
    "# Price impact in the limit order book \n",
    "\n",
    "$\\inf\\left\\{\\mathbb{E}\\left[\\sum_{n=0}^{N} \\left(D_n+\\frac{\\kappa}{2}x_n\\right)x_n + \\right]:\\sum_{n=0}^N x_n = X_0\\right\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a6f56e",
   "metadata": {},
   "source": [
    "# Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478a9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lob_params = {\n",
    "    'T':1,#time horizon\n",
    "    'mu':.3,\n",
    "    'gamma':.0,#permanent price impact zero\n",
    "    'kappa':1.,#temporary price impact\n",
    "    'rho':5.,#resilience rate\n",
    "    'sigma':.3,#volatility\n",
    "    'mu':.3,#drift\n",
    "    'A0':0.,# initial asset price\n",
    "    'balance':1e5,# initial balance\n",
    "}\n",
    "approx_params = {\n",
    "    'num_trajectories': 1000,#  number of simulated trajectories\n",
    "    'num_epochs': 3000, # number of epochs for training\n",
    "    'num_time_steps': 10, # number of time steps in each trajectory\n",
    "    'num_neurons': 16,# number of neurons in the hidden layers\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a7e56b",
   "metadata": {},
   "source": [
    "# Closed-form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95020ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class solution(object):\n",
    "    def __init__(self,lob_params,approx_params):\n",
    "        self.num_steps = approx_params['num_time_steps']\n",
    "        self.T = lob_params['T']\n",
    "        self.rho = lob_params['rho']\n",
    "        self.kappa = lob_params['kappa']\n",
    "        self.delta = self.T/self.num_steps\n",
    "        self.alpha=np.exp(-self.rho*self.delta)\n",
    "    def optimal(self,x_init):\n",
    "        t = torch.tensor([i*self.delta for i in range(self.num_steps+1)])\n",
    "        for i in range(x_init.shape[0]):\n",
    "            if i==0:\n",
    "                trade = ((1-(torch.where(t==0.0*self.delta,0,1)*torch.where(t==self.num_steps*self.delta,0,1))*self.alpha)*x_init[i]/((self.num_steps-1)*(1-self.alpha)+2)).unsqueeze(0)\n",
    "            else:\n",
    "                trade = torch.cat((trade,((1-(torch.where(t==0.0*self.delta,0,1)*torch.where(t==self.num_steps*self.delta,0,1))*self.alpha)*x_init[i]/((self.num_steps-1)*(1-self.alpha)+2)).unsqueeze(0)),axis=0)\n",
    "        return trade\n",
    "    def __call__(self, x):\n",
    "        exec =  self.optimal(x)   \n",
    "        c_tmp = torch.tensor([0.0])\n",
    "        D_tmp = torch.tensor([0.0])\n",
    "        for i in range(self.num_steps+1):\n",
    "            c_tmp = c_tmp + D_tmp*exec[:,i]+(self.kappa/2.0)*np.power(exec[:,i],2)\n",
    "            D_tmp = (D_tmp + self.kappa * exec[:,i])*self.alpha\n",
    "        return c_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc334cb",
   "metadata": {},
   "source": [
    "# Coarse PGM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99840d5",
   "metadata": {},
   "source": [
    "## Neural net for trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33429f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trade_net(nn.Module): #NN for trading strategy\n",
    "    def __init__(self,params):\n",
    "        self.dim = params['dim']\n",
    "        self.num_neurons = params['num_neurons']\n",
    "        super(trade_net, self).__init__()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(self.dim, self.num_neurons),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Linear(self.num_neurons, self.num_neurons),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Linear(self.num_neurons,1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits#.reshape([dim,dim])      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1dafa6",
   "metadata": {},
   "source": [
    "## Neural net for value function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aceb511",
   "metadata": {},
   "outputs": [],
   "source": [
    "class value_fnc(nn.Module): #NN for trading strategy\n",
    "    def __init__(self,params):\n",
    "        self.dim = params['dim']\n",
    "        self.num_neurons = params['num_neurons']\n",
    "        super(value_fnc, self).__init__()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(self.dim, self.num_neurons),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Linear(self.num_neurons, self.num_neurons),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Linear(self.num_neurons,1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits#.reshape([dim,dim])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab8f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class optimal_execution(object):\n",
    "    def __init__(self,lob_params,approx_params):\n",
    "        self.epoch = 0\n",
    "        self.loss_epoch=[]\n",
    "        self.M = approx_params['num_trajectories']\n",
    "        self.ite = approx_params['num_time_steps']\n",
    "        self.dim = approx_params['num_neurons']\n",
    "        self.T = lob_params['T']\n",
    "        self.sigma = lob_params['sigma']\n",
    "        self.mu = lob_params['mu']\n",
    "        self.A0 =lob_params['A0'] #initial fundamental price\n",
    "        self.gamma = lob_params['gamma'] # permanent price impact\n",
    "        self.kappa = lob_params['kappa'] #price impact coeff\n",
    "        self.rho = lob_params['rho'] #resillience\n",
    "        self.X0 = lob_params['balance']\n",
    "        self.neuron_model_psi = approx_params['num_neurons']\n",
    "        self.delta = self.T/self.ite\n",
    "        self.alpha = np.exp(-self.rho*self.delta)\n",
    "        self.trade_size = trade_net(approx_params)\n",
    "        self.V = value_fnc(approx_params)\n",
    "        t=torch.zeros([self.M,1])\n",
    "        D=torch.zeros([self.M,1])\n",
    "        R=self.X0*0.9+(self.X0*1.1-self.X0*0.9)*torch.rand(self.M,1)  #remaining balance R_t   #To get a positive solution R_t has to be greater than D_t\n",
    "        self.x=torch.cat((t,D,R),dim=1)\n",
    "        self.trained = False\n",
    "        # self.exit_dict = params # Write the result in this dict\n",
    "        self.cf = solution(lob_params, approx_params)#closed-form solution\n",
    "        \n",
    "        \n",
    "    # undate state process for one step\n",
    "    def update(self,x,psi):\n",
    "        t=(x[:,0]+self.delta)\n",
    "        D = (x[:,1]+self.kappa*psi)*self.alpha\n",
    "        R= x[:,2]-psi\n",
    "        up=torch.cat((t.unsqueeze(1),D.unsqueeze(1),R.unsqueeze(1)),dim=1)\n",
    "        return up\n",
    "    # running cost function for one step\n",
    "    def step_cost(self,x,psi):\n",
    "        loss=(x[:,1]*psi+(self.kappa/2.0)*torch.pow(psi,2))\n",
    "        return loss\n",
    "    # summarize the trade size, cost and update for one step\n",
    "    def unit(self,x):\n",
    "        psi=self.trade_size(x).squeeze(1)\n",
    "        loss=self.step_cost(x,psi)\n",
    "        upd=self.update(x,psi)\n",
    "        return psi, loss, upd\n",
    "    # total cost\n",
    "    def cost(self,x):\n",
    "        cost=torch.zeros(self.M,self.ite+1)\n",
    "        psi=torch.zeros(self.M,self.ite)\n",
    "        u=x\n",
    "        for i in range(self.ite+1):\n",
    "            if(i!=self.ite):\n",
    "                psi_run,loss_run,u_run=self.unit(u)\n",
    "                #print('los func=',psi_run.shape,loss_run.shape)\n",
    "                cost[:,i]=loss_run\n",
    "                #print(loss)\n",
    "                psi[:,i]=psi_run\n",
    "                #print(psi)\n",
    "                u=u_run\n",
    "                #print(u)\n",
    "            else:\n",
    "                # print(torch.sum(psi,dim=1).shape,x[:,2].shape)\n",
    "                # psi_ter=x[:,2]-torch.sum(psi,dim=1)\n",
    "                # psi_ter = u[:,2]\n",
    "                cost[:,i]=self.step_cost(u,u[:,2])\n",
    "                #print('ter',loss_ter.shape)\n",
    "        cost=torch.sum(cost,dim=1)\n",
    "        #print(loss.shape)\n",
    "        return cost\n",
    "    \n",
    "    def train(self, lr, err, num_epochs):\n",
    "        start=time.time()\n",
    "        # lr = 8e-3\n",
    "        epoch=self.epoch\n",
    "        # num_epochs=500\n",
    "        L_=-1000\n",
    "        optimizer = optim.Adam(self.trade_size.parameters(), lr)\n",
    "        L=100000\n",
    "        while (np.abs(L_-L)/np.abs(L_)>err) &  (epoch <= num_epochs):\n",
    "            t0 = time.time()\n",
    "            optimizer.zero_grad()\n",
    "            cost=self.cost(self.x)\n",
    "            loss = torch.mean(cost)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            L = loss.clone().detach().numpy()\n",
    "            self.loss_epoch.append(L)\n",
    "            if epoch>0:\n",
    "                L_ = self.loss_epoch[epoch-1]\n",
    "            if (epoch % int(num_epochs/5)== int(num_epochs/5)-1) | (epoch == 0):\n",
    "                print(\"At epoch {:,} the mean cost is {:.10E}.  Epoch training time = {:.2E} ms\".format(epoch+1,loss.detach(),1000*(time.time()-t0)))            \n",
    "            epoch=epoch+1\n",
    "        end=time.time()\n",
    "        print('time elapsed = {:.2e} ms'.format((end-start)*1000))\n",
    "        print(\"Relative change in loss = %{:.7E} , last epoch = {}.\".format((100*np.abs(L_-L)/np.abs(L_)),epoch+1))        \n",
    "        \n",
    "        \n",
    "    def gen_data(self):\n",
    "        if self.trained:\n",
    "            cost=torch.zeros(self.M,self.ite+1)\n",
    "            psi=torch.zeros(self.M,self.ite)\n",
    "            u=self.x\n",
    "            self.x_data = u\n",
    "            for i in range(self.ite+1):\n",
    "                if(i!=self.ite):\n",
    "                    if i >0:\n",
    "                        self.x_data = torch.cat((self.x_data,u),axis=0)\n",
    "                    psi_run,loss_run,u_run=self.unit(u) \n",
    "                    #print('los func=',psi_run.shape,loss_run.shape)\n",
    "                    cost[:,i]=loss_run\n",
    "                    #print(loss)\n",
    "                    psi[:,i]=psi_run\n",
    "                    #print(psi)\n",
    "                    u=u_run\n",
    "                    #print(u)\n",
    "                else:\n",
    "                    # print(torch.sum(psi,dim=1).shape,x[:,2].shape)\n",
    "                    # psi_ter=self.x[:,2]-torch.sum(psi,dim=1)\n",
    "                    cost[:,i]=self.step_cost(u,u[:,2])\n",
    "                    self.x_data = torch.cat((self.x_data,u),axis=0)\n",
    "                    #print('ter',loss_ter.shape)\n",
    "            self.y_data=torch.sum(cost,dim=1).unsqueeze(-1)\n",
    "            for i in range(self.ite):\n",
    "                self.y_data = torch.cat((self.y_data,torch.sum(cost[:,i+1:],dim=1).unsqueeze(-1)),axis=0)\n",
    "            r = torch.randperm(self.x_data.shape[0])\n",
    "            self.x_data = self.x_data[r,:].clone().detach()\n",
    "            self.y_data = self.y_data[r,:].clone().detach()  \n",
    "            self.exit_dict['data'] = self.x_data     \n",
    "        else:\n",
    "            self.train(8e-3,1e-7,3000)\n",
    "            self.gen_data()        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
